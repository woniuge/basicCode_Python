{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 UserCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from surprise import Reader\n",
    "from surprise import accuracy\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD,KNNBasic,KNNWithMeans,KNNWithZScore,SVDpp,AlgoBase,BaselineOnly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    使用ml-latest-small数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#moviesPath = 'datasets\\\\ml-latest-small\\\\movies.csv'\n",
    "ratingsPath = 'datasets\\\\ml-latest-small\\\\ratings.csv'\n",
    "#moviesDF = pd.read_csv(moviesPath,index_col=None)\n",
    "ratingsDF = pd.read_csv(ratingsPath,index_col=None).loc[:,['userId','movieId','rating']]\n",
    "\n",
    "# file_path = os.path.expanduser(\"D:\\\\DevelopSoft\\\\pycharm\\\\Projects\\\\Andrew_Ng\\\\Surprise\\\\firstPaper\\\\datasets\\\\ml-latest-small\\\\ratings.csv\")\n",
    "# reader = Reader(line_format='user item rating timestamp',sep=',')\n",
    "# data = Dataset.load_from_file(file_path,reader=reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 尝试一把使用Baselineonly()\n",
    "# cross_validate(BaselineOnly(),data,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 尝试一把使用SVD\n",
    "# algo = SVD()\n",
    "# cross_validate(algo,data,measures=['RMSE','MAE'],cv=5,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    数据集切分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating\n",
       "0       1        1     4.0\n",
       "1       1        3     4.0\n",
       "2       1        6     4.0\n",
       "3       1       47     5.0\n",
       "4       1       50     5.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratingsDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_movie_count:9724\n",
      "total_user_count:610\n",
      "train_movie_count:8133\n",
      "train_user_count:610\n",
      "crossValidation_movie_count:5073\n",
      "crossValidation_user_count:609\n",
      "test_movie_count:5134\n",
      "test_user_count:609\n"
     ]
    }
   ],
   "source": [
    "# 按照6:2:2的比例将数据集进行拆分，同时打印出总的用户和电影数量，\n",
    "# 训练集中的用户和电影数量，交叉验证集中的用户和电影数量，以及测试集中的用户和电影数量：\n",
    "trainRatDF,testRatingsDF = train_test_split(ratingsDF,test_size=0.2)\n",
    "trainRatingsDF,crossValidationRatingsDF = train_test_split(trainRatDF,test_size=0.25)\n",
    "\n",
    "print(\"total_movie_count:\"+str(len(set(ratingsDF['movieId'].values.tolist()))))\n",
    "print(\"total_user_count:\"+str(len(set(ratingsDF['userId'].values.tolist()))))\n",
    "print(\"train_movie_count:\"+str(len(set(trainRatingsDF['movieId'].values.tolist()))))\n",
    "print(\"train_user_count:\"+str(len(set(trainRatingsDF['userId'].values.tolist()))))\n",
    "print(\"crossValidation_movie_count:\"+str(len(set(crossValidationRatingsDF['movieId'].values.tolist()))))\n",
    "print(\"crossValidation_user_count:\"+str(len(set(crossValidationRatingsDF['userId'].values.tolist()))))\n",
    "print(\"test_movie_count:\"+str(len(set(testRatingsDF['movieId'].values.tolist()))))\n",
    "print(\"test_user_count:\"+str(len(set(testRatingsDF['userId'].values.tolist()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100836\n",
      "60501\n",
      "20167\n",
      "20168\n"
     ]
    }
   ],
   "source": [
    "print(len(ratingsDF))\n",
    "print(len(trainRatingsDF))\n",
    "print(len(crossValidationRatingsDF))\n",
    "print(len(testRatingsDF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>60501.000000</td>\n",
       "      <td>60501.000000</td>\n",
       "      <td>60501.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>325.461249</td>\n",
       "      <td>19485.160427</td>\n",
       "      <td>3.496248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>182.818644</td>\n",
       "      <td>35576.582652</td>\n",
       "      <td>1.044728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>177.000000</td>\n",
       "      <td>1198.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>325.000000</td>\n",
       "      <td>2987.000000</td>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>477.000000</td>\n",
       "      <td>8132.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>610.000000</td>\n",
       "      <td>193585.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             userId        movieId        rating\n",
       "count  60501.000000   60501.000000  60501.000000\n",
       "mean     325.461249   19485.160427      3.496248\n",
       "std      182.818644   35576.582652      1.044728\n",
       "min        1.000000       1.000000      0.500000\n",
       "25%      177.000000    1198.000000      3.000000\n",
       "50%      325.000000    2987.000000      3.500000\n",
       "75%      477.000000    8132.000000      4.000000\n",
       "max      610.000000  193585.000000      5.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainRatingsDF.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(0.5,5))\n",
    "traindata = Dataset.load_from_df(trainRatingsDF,reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = traindata.build_full_trainset()\n",
    "# algo = KNNBasic()\n",
    "# algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from surprise.model_selection import KFold\n",
    "\n",
    "# kf = KFold(n_splits=3)\n",
    "\n",
    "# algo = SVD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for trainset,testset in kf.split(traindata):\n",
    "#     # train and test algorithm.\n",
    "#     algo.fit(trainset)\n",
    "#     predictions = algo.test(testset)\n",
    "#     #print(predictions)\n",
    "    \n",
    "#     # compute and print Root Mean Squared Error\n",
    "#     accuracy.rmse(predictions,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 基于内容的推荐算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 此处仅用电影的题材类别表示电影内容\n",
    "moviesPath = 'datasets\\\\ml-latest-small\\\\movies.csv'\n",
    "\n",
    "moviesDF = pd.read_csv(moviesPath,index_col=None).loc[:,['movieId','genres']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                                       genres\n",
       "0        1  Adventure|Animation|Children|Comedy|Fantasy\n",
       "1        2                   Adventure|Children|Fantasy\n",
       "2        3                               Comedy|Romance\n",
       "3        4                         Comedy|Drama|Romance\n",
       "4        5                                       Comedy"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moviesDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_list = ['Action','Adventure','Animation','Children','Comedy','Crime','Documentary','Drama','Fantasy','Film-Noir','Horror','Musical','Mystery','Romance','Sci-Fi','Thriller','War','Western','IMAX','(no genres listed)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_int_map = {val: ii for ii, val in enumerate(genre_list)}\n",
    "# print(len(genre_int_map))\n",
    "# genre_int_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Adventure|Animation|Children|Comedy|Fantasy'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moviesDF.loc[0,'genres']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 电影题材可以视为多值属性，且类型不多，可以直接使用Multi-Hot编码\n",
    "def genres_multi_hot(genre_int_map):\n",
    "    \"\"\"\n",
    "    电影题材类型使用multi-hot编码\n",
    "    :param: genre_int_map:genre到数字的映射字典\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    def helper(genres):\n",
    "        genre_int_list = [genre_int_map[genre] for genre in genres.split('|')]\n",
    "        multi_hot = np.zeros(len(genre_int_map))\n",
    "        multi_hot[genre_int_list] = 1\n",
    "        return multi_hot\n",
    "\n",
    "    return helper\n",
    "\n",
    "moviesDF['genresMultiHot'] = moviesDF['genres'].map(genres_multi_hot(genre_int_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nmoviesDF['genres']=moviesDF['genres'].str.split('|')\\ngenre_list = ['Action','Adventure','Animation','Children','Comedy','Crime','Documentary','Drama','Fantasy','Film-Noir','Horror','Musical','Mystery','Romance','Sci-Fi','Thriller','War','Western','IMAX','(no genres listed)']\\ngenre_int_map = {val: ii for ii, val in enumerate(genre_list)}\\nprint(len(genre_int_map))\\ngenre_int_map\\n# 给moviesDF添加一列\\nmoviesDF['genresMultiHot'] = None\\nfor i in range(len(moviesDF)):\\n    genre_int_list = [genre_int_map[genre] for genre in moviesDF.loc[i,'genres']]\\n    multi_hot = np.zeros(len(genre_int_map))\\n    multi_hot[genre_int_list] = 1\\n    moviesDF.at[i,'genresMultiHot'] = multi_hot\\n\\nmoviesDF['genresMultiHot'][122]\\n\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 也可以不写函数，而是使用for循环遍历moviesDF\n",
    "'''\n",
    "moviesDF['genres']=moviesDF['genres'].str.split('|')\n",
    "genre_list = ['Action','Adventure','Animation','Children','Comedy','Crime','Documentary','Drama','Fantasy','Film-Noir','Horror','Musical','Mystery','Romance','Sci-Fi','Thriller','War','Western','IMAX','(no genres listed)']\n",
    "genre_int_map = {val: ii for ii, val in enumerate(genre_list)}\n",
    "print(len(genre_int_map))\n",
    "genre_int_map\n",
    "# 给moviesDF添加一列\n",
    "moviesDF['genresMultiHot'] = None\n",
    "for i in range(len(moviesDF)):\n",
    "    genre_int_list = [genre_int_map[genre] for genre in moviesDF.loc[i,'genres']]\n",
    "    multi_hot = np.zeros(len(genre_int_map))\n",
    "    multi_hot[genre_int_list] = 1\n",
    "    moviesDF.at[i,'genresMultiHot'] = multi_hot\n",
    "\n",
    "moviesDF['genresMultiHot'][122]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moviesDF['genresMultiHot'][122]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9742"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(moviesDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算电影内容的相似度矩阵并存入文件\n",
    "# 这里我们使用余弦相似度来计算电影之间的相似度关系\n",
    "def calCosineSimilarity(list1,list2):\n",
    "    res = 0\n",
    "    denominator1 = 0 # denominator分母\n",
    "    denominator2 = 0\n",
    "    for (val1,val2) in zip(list1,list2):\n",
    "        res += (val1 * val2)\n",
    "        denominator1 += val1 ** 2\n",
    "        denominator2 += val2 ** 2\n",
    "    return res / (np.sqrt(denominator1 * denominator2))   \n",
    "# 计算电影之间的相似度矩阵，对于用户相似度矩阵，这是一个对称矩阵，同时对角线的元素为1，所以我们只需要计算上三角矩阵的值即可\n",
    "movieSimMatrix = np.ones((len(moviesDF),len(moviesDF)),dtype=np.float32)\n",
    "for i in range(len(moviesDF)-1):\n",
    "    for j in range(i+1,len(moviesDF)):\n",
    "        movieSimMatrix[i,j] = calCosineSimilarity(moviesDF['genresMultiHot'][i],moviesDF['genresMultiHot'][j])\n",
    "        movieSimMatrix[j,i] = movieSimMatrix[i,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    2, ..., 9739, 9740, 9741])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = np.arange(len(moviesDF))\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.000e+00, 1.000e+00, 2.000e+00, ..., 9.739e+03, 9.740e+03,\n",
       "       9.741e+03], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movieSimMatrix = np.insert(movieSimMatrix,0,values=row,axis=0)\n",
    "movieSimMatrix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9742, 9742)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movieSimMatrix = np.delete(movieSimMatrix,0,axis=0)\n",
    "movieSimMatrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.7745967 , 0.31622776, ..., 0.        , 0.31622776,\n",
       "        0.4472136 ],\n",
       "       [0.7745967 , 1.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.31622776, 0.        , 1.        , ..., 0.        , 0.        ,\n",
       "        0.70710677],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.31622776, 0.        , 0.        , ..., 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.4472136 , 0.        , 0.70710677, ..., 0.        , 0.        ,\n",
       "        1.        ]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movieSimMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    2, ..., 9739, 9740, 9741])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = np.arange(len(moviesDF))\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9743,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = np.concatenate(([-1],col))\n",
    "col.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (9743,1) into shape (9742,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-1e3bd63c9cc2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmovieSimMatrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmovieSimMatrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\DevelopSoft\\Anaconda3\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36minsert\u001b[1;34m(arr, obj, values, axis)\u001b[0m\n\u001b[0;32m   5071\u001b[0m         \u001b[0mnew\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mslobj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mslobj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5072\u001b[0m         \u001b[0mslobj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mnumnew\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5073\u001b[1;33m         \u001b[0mnew\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mslobj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5074\u001b[0m         \u001b[0mslobj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mnumnew\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5075\u001b[0m         \u001b[0mslobj2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mndim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (9743,1) into shape (9742,1)"
     ]
    }
   ],
   "source": [
    "movieSimMatrix = np.insert(movieSimMatrix,0,values=col,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('datasets\\\\ml-latest-small\\\\movieSim.csv',movieSimMatrix,delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.741000e+03, 4.472136e-01, 0.000000e+00, ..., 0.000000e+00,\n",
       "       0.000000e+00, 1.000000e+00], dtype=float32)"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movieSimMatrix[9742]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]]\n",
      "120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a = np.zeros((1,1),dtype=np.float64)\n",
    "# import sys\n",
    "# print(a)\n",
    "# print(sys.getsizeof(a))\n",
    "# a.itemsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import sys\n",
    "# sys.getsizeof(movieSimMatrix[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# movieSimMatrix[0][0].nbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from six import get_unbound_function as guf\n",
    "\n",
    "class MyAlgoBase(AlgoBase):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        AlgoBase.__init__(self, **kwargs)\n",
    "        \n",
    "    def fit(self, trainset):\n",
    "        \n",
    "        if (guf(self.__class__.train) is not guf(AlgoBase.train) and\n",
    "                not self.skip_train):\n",
    "            self.train(trainset)\n",
    "            return \n",
    "        self.skip_train = False\n",
    "        \n",
    "        self.trainset = trainset\n",
    "        \n",
    "        self.bu = self.bi = None\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def compute_similarities(self, verbose=False):\n",
    "        \"\"\"Build the similarity matrix.\n",
    "        \n",
    "        The way the similarity matrix is computed depends on the \n",
    "        ''sim_options'' parameter passed at the creation of the algorithm (see\n",
    "        :ref:'similarity_measures_configuration')\n",
    "        \n",
    "        This methdod is only relevant for algorithms using a similarity measure,\n",
    "        such as the :ref:'k-NN algorithms <pred_package_knn_ispired>'.\n",
    "        \n",
    "        Args:\n",
    "            verbose(bool) : if ''True'',print status message. Default is ''False''.\n",
    "            \n",
    "        Returns:\n",
    "            The similarity matrix.\"\"\"\n",
    "            \n",
    "#         complex_sim_mat = pd.read_csv('D:\\\\Spyder\\\\surprise\\\\paper_code\\\\ml-latest-small-data\\\\LY_data\\\\complex_sim_df_82.csv')\n",
    "        complex_sim_mat = pd.read_csv('datasets\\\\ml-latest-small\\\\movieSim.csv')\n",
    "        complex_sim_mat = complex_sim_mat.set_index(['Unnamed: 0'])\n",
    "        complex_sim_mat.columns = list(complex_sim_mat.index)\n",
    "        \n",
    "        construction_func = {'cosine': sims.cosine,\n",
    "                             'msd':sims.msd,\n",
    "                             'pearson':sims.pearson,\n",
    "                             'pearson_baseline':sims.pearson_baseline}\n",
    "        \n",
    "        \n",
    "        if self.sim_options['user_based']:\n",
    "            n_x, yr = self.trainset.n_users, self.trainset.ir\n",
    "        else:\n",
    "            n_x, yr = self.trainset.n_items, self.trainset.ur\n",
    "            \n",
    "        min_support = self.sim_options.get('min_support', 1)\n",
    "        \n",
    "        args = [n_x, yr, min_support]\n",
    "        \n",
    "        \n",
    "        \n",
    "        name = self.sim_options.get('name', 'msd').lower()   \n",
    "        \n",
    "        \n",
    "        if name == 'pearson_baselines':\n",
    "            shrinkage = self.sim_options.get('shrinkage', 100)\n",
    "            bu, bi = self.compute_baselines()\n",
    "            if self.sim_options['user_based']:\n",
    "                bx, by = bu, bi\n",
    "            else:\n",
    "                bx, by = bi, bu\n",
    "                \n",
    "            args += [self.trainset.global_mean, bx, by, shrinkage]\n",
    "        \n",
    "            \n",
    "        try:\n",
    "            if verbose:\n",
    "                print('Computing the {0} similarity matrix...'.format(name))\n",
    "            sim = complex_sim_mat\n",
    "            if verbose:\n",
    "                print('Done computing similarity matrix.')\n",
    "            return sim\n",
    "        except KeyError:\n",
    "            raise NameError('Wrong sim name ' + name + '.Allowed values ' +\n",
    "                            'are ' + ', '.join(construction_func.keys()) + '.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySymmetricAlgo(MyAlgoBase):\n",
    "    \n",
    "    def __init__(self, sim_options={}, verbose=True, **kwargs):\n",
    "        MyAlgoBase.__init__(self, sim_options=sim_options, **kwargs)\n",
    "        self.verbose = verbose\n",
    "        \n",
    "    def fit(self, trainset):\n",
    "        MyAlgoBase.fit(self, trainset)\n",
    "        \n",
    "        ub = self.sim_options['user_based']\n",
    "        self.n_x = self.trainset.n_users if ub else self.trainset.n_items\n",
    "        self.n_y = self.trainset.n_items if ub else self.trainset.n_users\n",
    "        self.xr = self.trainset.ur if ub else self.trainset.ir\n",
    "        self.yr = self.trainset.ir if ub else self.trainset.ur\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def switch(self, u_stuff, i_stuff):\n",
    "        \n",
    "        if self.sim_options['user_based']:\n",
    "            return u_stuff, i_stuff\n",
    "        else:\n",
    "            return i_stuff, u_stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyKnnWithMeans(MySymmetricAlgo):\n",
    "    \n",
    "    def __init__(self, k=40, min_k=1, sim_options={}, verbose=True, **kwargs):\n",
    "\n",
    "        MySymmetricAlgo.__init__(self, sim_options=sim_options,\n",
    "                               verbose=verbose, **kwargs)\n",
    "\n",
    "        self.k = k\n",
    "        self.min_k = min_k\n",
    "        \n",
    "    def fit(self, trainset):\n",
    "\n",
    "        MySymmetricAlgo.fit(self, trainset)\n",
    "        self.sim = self.compute_similarities(verbose=self.verbose)\n",
    "\n",
    "        self.means = np.zeros(self.n_x)\n",
    "        for x, ratings in iteritems(self.xr):\n",
    "            self.means[x] = np.mean([r for (_, r) in ratings])\n",
    "\n",
    "        return self\n",
    "        \n",
    "    def estimate(self, u, i):\n",
    "\n",
    "        if not (self.trainset.knows_user(u) and self.trainset.knows_item(i)):\n",
    "            raise PredictionImpossible('User and/or item is unkown.')\n",
    "\n",
    "        x, y = self.switch(u, i)\n",
    "\n",
    "\n",
    "        #neighbors = [(x2, self.sim[x, x2], r) for (x2, r) in self.yr[y]]\n",
    "        #k_neighbors = heapq.nlargest(self.k, neighbors, key=lambda t: t[1])\n",
    "        \n",
    "        neighbors = [(x2, self.sim.loc[x, x2], r) for (x2, r) in self.yr[y]]\n",
    "        k_neighbors = heapq.nlargest(self.k, neighbors, key=lambda t: t[1])\n",
    "\n",
    "        est = self.means[x]\n",
    "\n",
    "        # compute weighted average\n",
    "        sum_sim = sum_ratings = actual_k = 0\n",
    "        for (nb, sim, r) in k_neighbors:\n",
    "            if sim > 0:\n",
    "                sum_sim += sim\n",
    "                sum_ratings += sim * (r - self.means[nb])\n",
    "                actual_k += 1\n",
    "\n",
    "        if actual_k < self.min_k:\n",
    "            sum_ratings = 0\n",
    "\n",
    "        try:\n",
    "            est += sum_ratings / sum_sim\n",
    "        except ZeroDivisionError:\n",
    "            pass  # return mean\n",
    "\n",
    "        details = {'actual_k': actual_k}\n",
    "        return est, details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_options = {'name': 'pearson',\n",
    "               'user_based': False  # compute  similarities between items\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = MyKnnWithMeans(sim_options=sim_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 9742 elements, new values have 9743 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-71435e67f2fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0malgo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-34-c1528afa0d67>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, trainset)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mMySymmetricAlgo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_similarities\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmeans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-32-0f50ff9d3be0>\u001b[0m in \u001b[0;36mcompute_similarities\u001b[1;34m(self, verbose)\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mcomplex_sim_mat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'datasets\\\\ml-latest-small\\\\movieSim.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mcomplex_sim_mat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomplex_sim_mat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Unnamed: 0'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mcomplex_sim_mat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomplex_sim_mat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         construction_func = {'cosine': sims.cosine,\n",
      "\u001b[1;32mD:\\DevelopSoft\\Anaconda3\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   5078\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5079\u001b[0m             \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5080\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5081\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5082\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mD:\\DevelopSoft\\Anaconda3\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_set_axis\u001b[1;34m(self, axis, labels)\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 638\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    639\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\DevelopSoft\\Anaconda3\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mset_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m    153\u001b[0m             raise ValueError(\n\u001b[0;32m    154\u001b[0m                 \u001b[1;34m'Length mismatch: Expected axis has {old} elements, new '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m                 'values have {new} elements'.format(old=old_len, new=new_len))\n\u001b[0m\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length mismatch: Expected axis has 9742 elements, new values have 9743 elements"
     ]
    }
   ],
   "source": [
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossValidationRatingsdata = Dataset.load_from_df(crossValidationRatingsDF,reader)\n",
    "crossValidationset = crossValidationRatingsdata.build_full_trainset().build_testset()\n",
    "predictions = algo.test(crossValidationset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossValidationRatingsDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_at_k(predictions, k=10, threshold=3.5):\n",
    "    '''Return precision and recall at k metrics for each user.'''\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "\n",
    "        # Sort user ratings by estimated value\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # Number of relevant items\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "\n",
    "        # Number of recommended items in top k\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "\n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
    "                              for (est, true_r) in user_ratings[:k])\n",
    "\n",
    "        # Precision@K: Proportion of recommended items that are relevant\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 1\n",
    "\n",
    "        # Recall@K: Proportion of relevant items that are recommended\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 1\n",
    "\n",
    "    return precisions, recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions, recalls = precision_recall_at_k(predictions, threshold=3.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_prec = sum(prec for prec in precisions.values()) / len(precisions)\n",
    "avg_recall = sum(rec for rec in recalls.values()) / len(recalls)\n",
    "avg_prec = round(avg_prec, 4)\n",
    "avg_recall = round(avg_recall, 4)\n",
    "rmse = round(accuracy.rmse(predictions), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
